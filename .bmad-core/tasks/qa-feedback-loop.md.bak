# QA Feedback Loop Task

## Purpose

Manage the iterative review cycle between QA and Dev agents when QA finds issues that need to be addressed. This task provides a structured process for handling QA feedback, implementing fixes, and re-requesting review until quality gates are met.

## When to Use

Use this task when:
- QA review results in CONCERNS or FAIL status
- Dev needs to implement fixes for QA findings
- Multiple review iterations are required
- Quality gates need to be re-evaluated

## Command Structure

### For Dev Agent: After QA Provides Feedback

```bash
# Command to execute when QA finds issues
# *qa-feedback
# or
*apply-qa-fixes {story-id}
```

**Example:**
```bash
# *qa-feedback
# or
*apply-qa-fixes story-001-cache-manager.md
```

### For QA Agent: After Dev Implements Fixes

```bash
# Command to re-review after fixes
*review {story-id}
# or
*gate {story-id}  # Update gate status only
```

## QA Feedback Types

### CONCERNS Status
**Definition**: Non-blocking issues that should be addressed but don't prevent deployment
**Examples**:
- Test coverage slightly below target
- Minor performance optimizations possible
- Code style improvements recommended

### FAIL Status
**Definition**: Critical issues that must be fixed before deployment
**Examples**:
- Acceptance criteria not met
- Security vulnerabilities
- Breaking API changes
- Test failures

### WAIVED Status
**Definition**: Issues acknowledged but accepted with business justification
**Examples**:
- Known limitations for MVP
- Technical debt accepted for timeline
- Risk mitigation documented

## Dev Agent: Implementing QA Fixes

### 1. Analyze QA Feedback

**Read QA Results from Story File:**
```markdown
## QA Results

### {timestamp} Quinn (QA) - Comprehensive Review
- **Decision:** CONCERNS – Minor issues identified
- **Findings:**
  - Issue 1: Description and severity
  - Issue 2: Description and severity
- **Gate Status:** docs/qa/gates/{epic}.{story}-{slug}.yml
```

**Read Gate File:**
```yaml
schema: 1
story: '1.1'
gate: CONCERNS
status_reason: 'Test coverage at 75%, target is 80%'
reviewer: 'Quinn'
updated: '2025-01-17T10:30:00Z'
top_issues:
  - id: 'TEST-001'
    severity: medium
    finding: 'Missing integration tests for API endpoints'
    suggested_action: 'Add integration test suite'
```

### 2. Create Fix Implementation Plan

**Priority Order for Fixes:**

1. **CRITICAL (FAIL status)**: Security issues, broken functionality, data corruption
2. **HIGH (FAIL status)**: Acceptance criteria violations, API breaking changes
3. **MEDIUM (CONCERNS/FAIL)**: Test coverage gaps, performance issues
4. **LOW (CONCERNS)**: Code style, documentation, minor optimizations

**Implementation Checklist:**
- [ ] Understand each QA finding and root cause
- [ ] Plan code/test changes needed
- [ ] Estimate effort and timeline
- [ ] Identify dependencies (new libraries, API changes)
- [ ] Plan testing strategy for fixes

### 3. Implement Fixes

**Code Changes:**
- Fix identified issues following QA recommendations
- Maintain existing code patterns and architecture
- Add new tests for fixed functionality
- Update documentation if APIs change

**Testing:**
- Run full test suite after each fix
- Add regression tests for fixed issues
- Verify performance improvements if applicable
- Test edge cases identified by QA

### 4. Update Story Documentation

**Dev Agent Record Updates:**
```markdown
### Completion Notes List
- {timestamp}: QA feedback implementation started
- Fixed {issue-1}: {description of fix}
- Added {test-type}: {description}
- Updated {documentation}: {what changed}

### File List
**Modified Files:**
- {file1} - Fixed {issue}, added {tests}
- {file2} - Updated {documentation}

**New Files:**
- {test-file} - Added {test-type} for {functionality}
```

**Story Status:**
- Keep status as "Review" until all fixes complete
- Change to "Done" only after QA approves fixes

### 5. Prepare for Re-Review

**Handoff to QA:**
```markdown
## QA Re-Review Request

**Previous QA Decision:** {CONCERNS/FAIL}
**Issues Addressed:**
1. {Issue 1}: ✅ Fixed - {brief description}
2. {Issue 2}: ✅ Fixed - {brief description}

**Testing Results:**
- All tests passing: {passed}/{total}
- New test coverage: +{percentage}%
- Performance benchmarks: {results}

**Files Changed:** {count} files
**Risk Assessment:** {Low/Medium/High} - {justification}
```

## QA Agent: Re-Review Process

### 1. Validate Fixes

**Check Each QA Finding:**
- [ ] Issue resolved completely
- [ ] Fix follows recommended approach
- [ ] No new issues introduced
- [ ] Tests added/updated appropriately

**Review Code Quality:**
- [ ] Fixes maintain code standards
- [ ] No regressions in existing functionality
- [ ] Documentation updated appropriately
- [ ] Performance requirements still met

### 2. Update QA Assessment

**Re-evaluate Gate Status:**
- **PASS**: All issues resolved, quality gates met
- **CONCERNS**: Minor issues remain, acceptable for deployment
- **FAIL**: Critical issues still present
- **WAIVED**: Issues accepted with business justification

**Update QA Results:**
```markdown
### {timestamp} Quinn (QA) - Re-Review After Fixes
- **Decision:** PASS – All issues resolved satisfactorily
- **Fixes Validated:**
  - ✅ Issue 1: Fixed correctly, tests added
  - ✅ Issue 2: Performance improved, benchmarks met
- **New Findings:** None
- **Gate Status:** docs/qa/gates/{epic}.{story}-{slug}.yml
```

### 3. Final Gate Update

**Update Gate File:**
```yaml
schema: 1
story: '1.1'
gate: PASS  # Updated from CONCERNS
status_reason: 'All QA feedback addressed, quality gates met'
reviewer: 'Quinn'
updated: '2025-01-17T14:30:00Z'
# Previous top_issues marked as resolved
```

## Iterative Review Cycle

### Round 1: Initial Review
```
Dev → QA Review → CONCERNS/FAIL → Dev Fixes → QA Re-Review
```

### Round 2+: Subsequent Reviews
```
Dev → QA Review → CONCERNS/FAIL → Dev Fixes → QA Re-Review
(Repeat until PASS or WAIVED)
```

### Maximum Iterations
- **Soft Limit**: 3 review cycles
- **Hard Limit**: 5 review cycles
- **Escalation**: Beyond 3 cycles, involve PO/SM for decision

## Success Criteria

### For Dev Agent
- [ ] All QA findings addressed with evidence
- [ ] Code changes follow QA recommendations
- [ ] Tests added for fixed functionality
- [ ] No regressions in existing features
- [ ] Story documentation updated accurately

### For QA Agent
- [ ] All original issues resolved or properly justified
- [ ] Code quality maintained or improved
- [ ] Test coverage adequate for changes
- [ ] No new critical issues introduced
- [ ] Gate status accurately reflects quality state

## Process Flow Diagram

```mermaid
graph TD
    A[QA Review: CONCERNS/FAIL] --> B[Dev: Analyze Feedback]
    B --> C[Dev: Create Fix Plan]
    C --> D[Dev: Implement Fixes]
    D --> E[Dev: Test & Validate]
    E --> F[Dev: Update Story Docs]
    F --> G[Dev: Request Re-Review]
    G --> H[QA: Validate Fixes]
    H --> I{QA Decision}
    I -->|PASS| J[Story: Done]
    I -->|CONCERNS/FAIL| B
    I -->|WAIVED| K[Document Justification]
    K --> J
```

## Command Reference

| Agent | Command | Purpose | When Used |
|-------|---------|---------|-----------|
| Dev | `# *qa-feedback` | Apply QA fixes systematically | After QA finds issues |
| Dev | `*qa-handoff` | Request re-review after fixes | After implementing fixes |
| QA | `*review {story}` | Comprehensive re-review | After dev implements fixes |
| QA | `*gate {story}` | Update gate status only | For minor gate updates |

## Best Practices

### For Dev Agents
- Address highest priority issues first
- Provide evidence of fixes in handoff
- Test thoroughly before re-requesting review
- Document rationale for any deviations from QA recommendations

### For QA Agents
- Clearly communicate what needs to be fixed
- Provide specific, actionable feedback
- Review fixes systematically
- Document any new findings discovered during re-review

### For Teams
- Keep review cycles short (< 2 days per iteration)
- Escalate stalled reviews to SM/PO
- Celebrate successful fix implementations
- Use feedback to improve future development practices

## Troubleshooting

### Common Issues

**"Fixes implemented but QA still fails"**
- Verify fix addresses root cause, not just symptoms
- Check if fix introduces new issues
- Review test cases to ensure they validate the fix

**"Dev and QA disagree on fix approach"**
- Escalate to SM for technical discussion
- Involve PO for business impact assessment
- Document agreed-upon approach in story

**"Multiple review cycles without progress"**
- Assess if issues are fundamental design problems
- Consider story scope adjustment
- Involve architect for major design changes

## Integration with Development Workflow

This feedback loop integrates with the overall development process:

1. **SM** creates story → **Dev** implements → **QA** reviews
2. **QA** finds issues → **Dev** fixes → **QA** re-reviews
3. **QA** approves → **SM** can create next story
4. **Repeat** until all stories in epic complete

The feedback loop ensures quality gates are maintained while allowing for iterative improvement and learning.
